From 53ff776580b423da83ce5612ff5eee95e4a7d2b6 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?R=C3=A9mi=20Bernon?= <rbernon@codeweavers.com>
Date: Sat, 21 May 2022 13:00:55 +0200
Subject: [PATCH 1/8] ntdll: Implement HeapCompatibilityInformation for
 Rtl(Query|Set)HeapInformation.

---
 dlls/kernel32/tests/heap.c | 10 ------
 dlls/ntdll/heap.c          | 70 ++++++++++++++++++++++++++++++--------
 2 files changed, 56 insertions(+), 24 deletions(-)

diff --git a/dlls/kernel32/tests/heap.c b/dlls/kernel32/tests/heap.c
index 83daa4dafa1..56c26a3e946 100644
--- a/dlls/kernel32/tests/heap.c
+++ b/dlls/kernel32/tests/heap.c
@@ -826,11 +826,8 @@ static void test_HeapCreate(void)
     size = 0;
     SetLastError( 0xdeadbeef );
     ret = pHeapQueryInformation( 0, HeapCompatibilityInformation, &compat_info, sizeof(compat_info), &size );
-    todo_wine
     ok( !ret, "HeapQueryInformation succeeded\n" );
-    todo_wine
     ok( GetLastError() == ERROR_NOACCESS, "got error %lu\n", GetLastError() );
-    todo_wine
     ok( size == 0, "got size %Iu\n", size );
 
     size = 0;
@@ -870,7 +867,6 @@ static void test_HeapCreate(void)
     ok( ret, "HeapSetInformation failed, error %lu\n", GetLastError() );
     ret = pHeapQueryInformation( heap, HeapCompatibilityInformation, &compat_info, sizeof(compat_info), &size );
     ok( ret, "HeapQueryInformation failed, error %lu\n", GetLastError() );
-    todo_wine
     ok( compat_info == 2, "got HeapCompatibilityInformation %lu\n", compat_info );
 
     /* cannot be undone */
@@ -878,20 +874,15 @@ static void test_HeapCreate(void)
     compat_info = 0;
     SetLastError( 0xdeadbeef );
     ret = pHeapSetInformation( heap, HeapCompatibilityInformation, &compat_info, sizeof(compat_info) );
-    todo_wine
     ok( !ret, "HeapSetInformation succeeded\n" );
-    todo_wine
     ok( GetLastError() == ERROR_GEN_FAILURE, "got error %lu\n", GetLastError() );
     compat_info = 1;
     SetLastError( 0xdeadbeef );
     ret = pHeapSetInformation( heap, HeapCompatibilityInformation, &compat_info, sizeof(compat_info) );
-    todo_wine
     ok( !ret, "HeapSetInformation succeeded\n" );
-    todo_wine
     ok( GetLastError() == ERROR_GEN_FAILURE, "got error %lu\n", GetLastError() );
     ret = pHeapQueryInformation( heap, HeapCompatibilityInformation, &compat_info, sizeof(compat_info), &size );
     ok( ret, "HeapQueryInformation failed, error %lu\n", GetLastError() );
-    todo_wine
     ok( compat_info == 2, "got HeapCompatibilityInformation %lu\n", compat_info );
 
     ret = HeapDestroy( heap );
@@ -930,7 +921,6 @@ static void test_HeapCreate(void)
     ok( ret, "HeapSetInformation failed, error %lu\n", GetLastError() );
     ret = pHeapQueryInformation( heap, HeapCompatibilityInformation, &compat_info, sizeof(compat_info), &size );
     ok( ret, "HeapQueryInformation failed, error %lu\n", GetLastError() );
-    todo_wine
     ok( compat_info == 2, "got HeapCompatibilityInformation %lu\n", compat_info );
 
     for (i = 0; i < 0x11; i++) ptrs[i] = pHeapAlloc( heap, 0, 24 + 2 * sizeof(void *) );
diff --git a/dlls/ntdll/heap.c b/dlls/ntdll/heap.c
index ef91096f258..99776aebc3d 100644
--- a/dlls/ntdll/heap.c
+++ b/dlls/ntdll/heap.c
@@ -39,6 +39,13 @@
 
 WINE_DEFAULT_DEBUG_CHANNEL(heap);
 
+/* HeapCompatibilityInformation values */
+
+#define HEAP_STD 0
+#define HEAP_LAL 1
+#define HEAP_LFH 2
+
+
 /* undocumented RtlWalkHeap structure */
 
 struct rtl_heap_entry
@@ -187,6 +194,7 @@ struct heap
     /* end of the Windows 10 compatible struct layout */
 
     BOOL             shared;        /* System shared heap */
+    LONG             compat_info;   /* HeapCompatibilityInformation / heap frontend type */
     struct list      entry;         /* Entry in process heap list */
     struct list      subheap_list;  /* Sub-heap list */
     struct list      large_list;    /* Large blocks list */
@@ -956,6 +964,7 @@ static SUBHEAP *HEAP_CreateSubHeap( struct heap **heap_ptr, LPVOID address, DWOR
         heap->auto_flags    = (flags & HEAP_GROWABLE);
         heap->flags         = (flags & ~HEAP_SHARED);
         heap->shared        = (flags & HEAP_SHARED) != 0;
+        heap->compat_info   = HEAP_STD;
         heap->magic         = HEAP_MAGIC;
         heap->grow_size     = max( HEAP_DEF_SIZE, totalSize );
         heap->min_size      = commitSize;
@@ -1545,11 +1554,13 @@ void *WINAPI DECLSPEC_HOTPATCH RtlAllocateHeap( HANDLE handle, ULONG flags, SIZE
 
     if (!(heap = unsafe_heap_from_handle( handle )))
         status = STATUS_INVALID_HANDLE;
-    else
+    else switch (InterlockedOr( &heap->compat_info, 0 ))
     {
+    default:
         heap_lock( heap, flags );
         status = heap_allocate( heap, heap_get_flags( heap, flags ), size, &ptr );
         heap_unlock( heap, flags );
+        break;
     }
 
     if (!status) valgrind_notify_alloc( ptr, size, flags & HEAP_ZERO_MEMORY );
@@ -1586,11 +1597,13 @@ BOOLEAN WINAPI DECLSPEC_HOTPATCH RtlFreeHeap( HANDLE handle, ULONG flags, void *
 
     if (!(heap = unsafe_heap_from_handle( handle )))
         status = STATUS_INVALID_PARAMETER;
-    else
+    else switch (InterlockedOr( &heap->compat_info, 0 ))
     {
+    default:
         heap_lock( heap, flags );
         status = heap_free( heap, ptr );
         heap_unlock( heap, flags );
+        break;
     }
 
     TRACE( "handle %p, flags %#x, ptr %p, return %u, status %#x.\n", handle, flags, ptr, !status, status );
@@ -1670,11 +1683,13 @@ void *WINAPI RtlReAllocateHeap( HANDLE handle, ULONG flags, void *ptr, SIZE_T si
 
     if (!(heap = unsafe_heap_from_handle( handle )))
         status = STATUS_INVALID_HANDLE;
-    else
+    else switch (InterlockedOr( &heap->compat_info, 0 ))
     {
+    default:
         heap_lock( heap, flags );
         status = heap_reallocate( heap, heap_get_flags( heap, flags ), ptr, size, &ret );
         heap_unlock( heap, flags );
+        break;
     }
 
     TRACE( "handle %p, flags %#x, ptr %p, size %#Ix, return %p, status %#x.\n", handle, flags, ptr, size, ret, status );
@@ -1775,11 +1790,13 @@ SIZE_T WINAPI RtlSizeHeap( HANDLE handle, ULONG flags, const void *ptr )
 
     if (!(heap = unsafe_heap_from_handle( handle )))
         status = STATUS_INVALID_PARAMETER;
-    else
+    else switch (InterlockedOr( &heap->compat_info, 0 ))
     {
+    default:
         heap_lock( heap, flags );
         status = heap_size( heap, ptr, &size );
         heap_unlock( heap, flags );
+        break;
     }
 
     TRACE( "handle %p, flags %#x, ptr %p, return %#Ix, status %#x.\n", handle, flags, ptr, size, status );
@@ -1799,12 +1816,14 @@ BOOLEAN WINAPI RtlValidateHeap( HANDLE handle, ULONG flags, const void *ptr )
 
     if (!(heap = unsafe_heap_from_handle( handle )))
         ret = FALSE;
-    else
+    else switch (InterlockedOr( &heap->compat_info, 0 ))
     {
+    default:
         heap_lock( heap, flags );
         if (ptr) ret = heap_validate_ptr( heap, ptr, &subheap );
         else ret = heap_validate( heap );
         heap_unlock( heap, flags );
+        break;
     }
 
     TRACE( "handle %p, flags %#x, ptr %p, return %u.\n", handle, flags, ptr, !!ret );
@@ -1975,21 +1994,23 @@ ULONG WINAPI RtlGetProcessHeaps( ULONG count, HANDLE *heaps )
  *           RtlQueryHeapInformation    (NTDLL.@)
  */
 NTSTATUS WINAPI RtlQueryHeapInformation( HANDLE handle, HEAP_INFORMATION_CLASS info_class,
-                                         void *info, SIZE_T size_in, PSIZE_T size_out )
+                                         void *info, SIZE_T size_in, SIZE_T *size_out )
 {
+    struct heap *heap;
+
+    TRACE( "handle %p, info_class %u, info %p, size_in %Iu, size_out %p.\n", handle, info_class, info, size_in, size_out );
+
     switch (info_class)
     {
     case HeapCompatibilityInformation:
+        if (!(heap = unsafe_heap_from_handle( handle ))) return STATUS_ACCESS_VIOLATION;
         if (size_out) *size_out = sizeof(ULONG);
-
-        if (size_in < sizeof(ULONG))
-            return STATUS_BUFFER_TOO_SMALL;
-
-        *(ULONG *)info = 0; /* standard heap */
+        if (size_in < sizeof(ULONG)) return STATUS_BUFFER_TOO_SMALL;
+        *(ULONG *)info = InterlockedOr( &heap->compat_info, 0 );
         return STATUS_SUCCESS;
 
     default:
-        FIXME("Unknown heap information class %u\n", info_class);
+        FIXME( "HEAP_INFORMATION_CLASS %u not implemented!\n", info_class );
         return STATUS_INVALID_INFO_CLASS;
     }
 }
@@ -1999,8 +2020,29 @@ NTSTATUS WINAPI RtlQueryHeapInformation( HANDLE handle, HEAP_INFORMATION_CLASS i
  */
 NTSTATUS WINAPI RtlSetHeapInformation( HANDLE handle, HEAP_INFORMATION_CLASS info_class, void *info, SIZE_T size )
 {
-    FIXME( "handle %p, info_class %d, info %p, size %ld stub!\n", handle, info_class, info, size );
-    return STATUS_SUCCESS;
+    struct heap *heap;
+
+    TRACE( "handle %p, info_class %u, info %p, size %Iu.\n", handle, info_class, info, size );
+
+    switch (info_class)
+    {
+    case HeapCompatibilityInformation:
+        if (size < sizeof(ULONG)) return STATUS_BUFFER_TOO_SMALL;
+        if (!(heap = unsafe_heap_from_handle( handle ))) return STATUS_INVALID_HANDLE;
+
+        if (*(ULONG *)info != 0 && *(ULONG *)info != HEAP_LFH)
+        {
+            FIXME( "HeapCompatibilityInformation %u not implemented!\n", *(ULONG *)info );
+            return STATUS_UNSUCCESSFUL;
+        }
+
+        if (InterlockedCompareExchange( &heap->compat_info, *(ULONG *)info, 0 )) return STATUS_UNSUCCESSFUL;
+        return STATUS_SUCCESS;
+
+    default:
+        FIXME( "HEAP_INFORMATION_CLASS %u not implemented!\n", info_class );
+        return STATUS_SUCCESS;
+    }
 }
 
 /***********************************************************************

From 7f0baa25da1d537bfda5ad91d87efe1c6044283f Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?R=C3=A9mi=20Bernon?= <rbernon@codeweavers.com>
Date: Wed, 28 Aug 2019 22:24:40 +0200
Subject: [PATCH 2/8] ntdll: Add thread destroy notification function.

This will be used in LFH to recycle the thread local data.
---
 dlls/ntdll/heap.c       | 4 ++++
 dlls/ntdll/loader.c     | 1 +
 dlls/ntdll/ntdll_misc.h | 2 ++
 dlls/ntdll/thread.c     | 1 +
 4 files changed, 8 insertions(+)

diff --git a/dlls/ntdll/heap.c b/dlls/ntdll/heap.c
index 99776aebc3d..d025432044b 100644
--- a/dlls/ntdll/heap.c
+++ b/dlls/ntdll/heap.c
@@ -2121,3 +2121,7 @@ BOOLEAN WINAPI RtlSetUserFlagsHeap( HANDLE handle, ULONG flags, void *ptr, ULONG
     FIXME( "handle %p, flags %#x, ptr %p, clear %#x, set %#x stub!\n", handle, flags, ptr, clear, set );
     return FALSE;
 }
+
+void HEAP_notify_thread_destroy( BOOLEAN last )
+{
+}
diff --git a/dlls/ntdll/loader.c b/dlls/ntdll/loader.c
index cc8313b30c6..e27666b71f3 100644
--- a/dlls/ntdll/loader.c
+++ b/dlls/ntdll/loader.c
@@ -3668,6 +3668,7 @@ void WINAPI RtlExitUserProcess( DWORD status )
     RtlAcquirePebLock();
     NtTerminateProcess( 0, status );
     LdrShutdownProcess();
+    HEAP_notify_thread_destroy(TRUE);
     for (;;) NtTerminateProcess( GetCurrentProcess(), status );
 }
 
diff --git a/dlls/ntdll/ntdll_misc.h b/dlls/ntdll/ntdll_misc.h
index d55083ae34c..0d4bf281b92 100644
--- a/dlls/ntdll/ntdll_misc.h
+++ b/dlls/ntdll/ntdll_misc.h
@@ -110,6 +110,8 @@ static inline TEB64 *NtCurrentTeb64(void) { return NULL; }
 static inline TEB64 *NtCurrentTeb64(void) { return (TEB64 *)NtCurrentTeb()->GdiBatchCount; }
 #endif
 
+void HEAP_notify_thread_destroy( BOOLEAN last );
+
 #define HASH_STRING_ALGORITHM_DEFAULT  0
 #define HASH_STRING_ALGORITHM_X65599   1
 #define HASH_STRING_ALGORITHM_INVALID  0xffffffff
diff --git a/dlls/ntdll/thread.c b/dlls/ntdll/thread.c
index 0ef7024a0e1..1b2c0381b4c 100644
--- a/dlls/ntdll/thread.c
+++ b/dlls/ntdll/thread.c
@@ -207,6 +207,7 @@ void WINAPI RtlExitUserThread( ULONG status )
     NtQueryInformationThread( GetCurrentThread(), ThreadAmILastThread, &last, sizeof(last), NULL );
     if (last) RtlExitUserProcess( status );
     LdrShutdownThread();
+    HEAP_notify_thread_destroy(FALSE);
     for (;;) NtTerminateThread( GetCurrentThread(), status );
 }
 

From 08be5996f84f9dc796773b36e25556492cef9ac2 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?R=C3=A9mi=20Bernon?= <rbernon@codeweavers.com>
Date: Thu, 28 Apr 2022 12:56:18 +0200
Subject: [PATCH 3/8] ntdll: Add extended heap type and LFH stubs.

---
 dlls/ntdll/Makefile.in  |  1 +
 dlls/ntdll/heap.c       | 80 +++++++++++++++++++++++++++++------------
 dlls/ntdll/heap_lfh.c   | 67 ++++++++++++++++++++++++++++++++++
 dlls/ntdll/ntdll_misc.h | 14 ++++++++
 4 files changed, 139 insertions(+), 23 deletions(-)
 create mode 100644 dlls/ntdll/heap_lfh.c

diff --git a/dlls/ntdll/Makefile.in b/dlls/ntdll/Makefile.in
index 3775749b0c5..a6c98f4d2d0 100644
--- a/dlls/ntdll/Makefile.in
+++ b/dlls/ntdll/Makefile.in
@@ -19,6 +19,7 @@ C_SRCS = \
 	exception.c \
 	handletable.c \
 	heap.c \
+	heap_lfh.c \
 	large_int.c \
 	loader.c \
 	locale.c \
diff --git a/dlls/ntdll/heap.c b/dlls/ntdll/heap.c
index d025432044b..7cedb07d3ad 100644
--- a/dlls/ntdll/heap.c
+++ b/dlls/ntdll/heap.c
@@ -1366,6 +1366,8 @@ static void heap_set_debug_flags( HANDLE handle )
                                               MAX_FREE_PENDING * sizeof(*heap->pending_free) );
         heap->pending_pos = 0;
     }
+
+    HEAP_lfh_set_debug_flags( flags );
 }
 
 
@@ -1556,6 +1558,9 @@ void *WINAPI DECLSPEC_HOTPATCH RtlAllocateHeap( HANDLE handle, ULONG flags, SIZE
         status = STATUS_INVALID_HANDLE;
     else switch (InterlockedOr( &heap->compat_info, 0 ))
     {
+    case HEAP_LFH:
+        if (!(status = HEAP_lfh_allocate( heap, heap_get_flags( heap, flags ), size, &ptr ))) break;
+        /* fallthrough */
     default:
         heap_lock( heap, flags );
         status = heap_allocate( heap, heap_get_flags( heap, flags ), size, &ptr );
@@ -1599,6 +1604,9 @@ BOOLEAN WINAPI DECLSPEC_HOTPATCH RtlFreeHeap( HANDLE handle, ULONG flags, void *
         status = STATUS_INVALID_PARAMETER;
     else switch (InterlockedOr( &heap->compat_info, 0 ))
     {
+    case HEAP_LFH:
+        if (!(status = HEAP_lfh_free( heap, heap_get_flags( heap, flags ), ptr ))) break;
+        /* fallthrough */
     default:
         heap_lock( heap, flags );
         status = heap_free( heap, ptr );
@@ -1685,6 +1693,9 @@ void *WINAPI RtlReAllocateHeap( HANDLE handle, ULONG flags, void *ptr, SIZE_T si
         status = STATUS_INVALID_HANDLE;
     else switch (InterlockedOr( &heap->compat_info, 0 ))
     {
+    case HEAP_LFH:
+        if (!(status = HEAP_lfh_reallocate( heap, flags, ptr, size, &ret ))) break;
+        /* fallthrough */
     default:
         heap_lock( heap, flags );
         status = heap_reallocate( heap, heap_get_flags( heap, flags ), ptr, size, &ret );
@@ -1792,6 +1803,9 @@ SIZE_T WINAPI RtlSizeHeap( HANDLE handle, ULONG flags, const void *ptr )
         status = STATUS_INVALID_PARAMETER;
     else switch (InterlockedOr( &heap->compat_info, 0 ))
     {
+    case HEAP_LFH:
+        if (!(status = HEAP_lfh_get_allocated_size( heap, heap_get_flags( heap, flags ), ptr, &size ))) break;
+        /* fallthrough */
     default:
         heap_lock( heap, flags );
         status = heap_size( heap, ptr, &size );
@@ -1818,6 +1832,9 @@ BOOLEAN WINAPI RtlValidateHeap( HANDLE handle, ULONG flags, const void *ptr )
         ret = FALSE;
     else switch (InterlockedOr( &heap->compat_info, 0 ))
     {
+    case HEAP_LFH:
+        if ((ret = !HEAP_lfh_validate( heap, heap_get_flags( heap, flags ), ptr ))) break;
+        /* fallthrough */
     default:
         heap_lock( heap, flags );
         if (ptr) ret = heap_validate_ptr( heap, ptr, &subheap );
@@ -2063,19 +2080,27 @@ BOOLEAN WINAPI RtlGetUserInfoHeap( HANDLE handle, ULONG flags, void *ptr, void *
 
     if (!(heap = unsafe_heap_from_handle( handle ))) return TRUE;
 
-    heap_lock( heap, flags );
-    if ((block = unsafe_block_from_ptr( heap, ptr, &subheap )) && !subheap)
-    {
-        const ARENA_LARGE *large = CONTAINING_RECORD( block, ARENA_LARGE, block );
-        *user_value = large->user_value;
-    }
-    else if (block)
+    switch (InterlockedOr( &heap->compat_info, 0 ))
     {
-        tmp = (char *)block + block_get_size( block ) - block->tail_size + sizeof(void *);
-        if ((heap_get_flags( heap, flags ) & HEAP_TAIL_CHECKING_ENABLED) || RUNNING_ON_VALGRIND) tmp += ALIGNMENT;
-        *user_value = *(void **)tmp;
+    case HEAP_LFH:
+        if (!HEAP_lfh_get_user_info( heap, heap_get_flags( heap, flags ), ptr, user_value )) break;
+        /* fallthrough */
+    default:
+        heap_lock( heap, flags );
+        if ((block = unsafe_block_from_ptr( heap, ptr, &subheap )) && !subheap)
+        {
+            const ARENA_LARGE *large = CONTAINING_RECORD( block, ARENA_LARGE, block );
+            *user_value = large->user_value;
+        }
+        else if (block)
+        {
+            tmp = (char *)block + block_get_size( block ) - block->tail_size + sizeof(void *);
+            if ((heap_get_flags( heap, flags ) & HEAP_TAIL_CHECKING_ENABLED) || RUNNING_ON_VALGRIND) tmp += ALIGNMENT;
+            *user_value = *(void **)tmp;
+        }
+        heap_unlock( heap, flags );
+        break;
     }
-    heap_unlock( heap, flags );
 
     return TRUE;
 }
@@ -2095,20 +2120,28 @@ BOOLEAN WINAPI RtlSetUserValueHeap( HANDLE handle, ULONG flags, void *ptr, void
 
     if (!(heap = unsafe_heap_from_handle( handle ))) return TRUE;
 
-    heap_lock( heap, flags );
-    if (!(block = unsafe_block_from_ptr( heap, ptr, &subheap ))) ret = FALSE;
-    else if (!subheap)
+    switch (InterlockedOr( &heap->compat_info, 0 ))
     {
-        ARENA_LARGE *large = CONTAINING_RECORD( block, ARENA_LARGE, block );
-        large->user_value = user_value;
-    }
-    else
-    {
-        tmp = (char *)block + block_get_size( block ) - block->tail_size + sizeof(void *);
-        if ((heap_get_flags( heap, flags ) & HEAP_TAIL_CHECKING_ENABLED) || RUNNING_ON_VALGRIND) tmp += ALIGNMENT;
-        *(void **)tmp = user_value;
+    case HEAP_LFH:
+        if ((ret = !HEAP_lfh_set_user_info( heap, heap_get_flags( heap, flags ), ptr, user_value ))) break;
+        /* fallthrough */
+    default:
+        heap_lock( heap, flags );
+        if (!(block = unsafe_block_from_ptr( heap, ptr, &subheap ))) ret = FALSE;
+        else if (!subheap)
+        {
+            ARENA_LARGE *large = CONTAINING_RECORD( block, ARENA_LARGE, block );
+            large->user_value = user_value;
+        }
+        else
+        {
+            tmp = (char *)block + block_get_size( block ) - block->tail_size + sizeof(void *);
+            if ((heap_get_flags( heap, flags ) & HEAP_TAIL_CHECKING_ENABLED) || RUNNING_ON_VALGRIND) tmp += ALIGNMENT;
+            *(void **)tmp = user_value;
+        }
+        heap_unlock( heap, flags );
+        break;
     }
-    heap_unlock( heap, flags );
 
     return ret;
 }
@@ -2124,4 +2157,5 @@ BOOLEAN WINAPI RtlSetUserFlagsHeap( HANDLE handle, ULONG flags, void *ptr, ULONG
 
 void HEAP_notify_thread_destroy( BOOLEAN last )
 {
+    HEAP_lfh_notify_thread_destroy( last );
 }
diff --git a/dlls/ntdll/heap_lfh.c b/dlls/ntdll/heap_lfh.c
new file mode 100644
index 00000000000..47a0f14e4b5
--- /dev/null
+++ b/dlls/ntdll/heap_lfh.c
@@ -0,0 +1,67 @@
+/*
+ * Wine Low Fragmentation Heap
+ *
+ * Copyright 2020 Remi Bernon for CodeWeavers
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301, USA
+ */
+
+#include "ntstatus.h"
+#define WIN32_NO_STATUS
+
+#include "ntdll_misc.h"
+
+NTSTATUS HEAP_lfh_allocate( HANDLE std_heap, ULONG flags, SIZE_T size, void **out )
+{
+    return STATUS_NOT_IMPLEMENTED;
+}
+
+NTSTATUS HEAP_lfh_free( HANDLE std_heap, ULONG flags, void *ptr )
+{
+    return STATUS_NOT_IMPLEMENTED;
+}
+
+NTSTATUS HEAP_lfh_reallocate( HANDLE std_heap, ULONG flags, void *ptr, SIZE_T size, void **out )
+{
+    return STATUS_NOT_IMPLEMENTED;
+}
+
+NTSTATUS HEAP_lfh_get_allocated_size( HANDLE std_heap, ULONG flags, const void *ptr, SIZE_T *out )
+{
+    return STATUS_NOT_IMPLEMENTED;
+}
+
+NTSTATUS HEAP_lfh_validate( HANDLE std_heap, ULONG flags, const void *ptr )
+{
+    return STATUS_NOT_IMPLEMENTED;
+}
+
+NTSTATUS HEAP_lfh_get_user_info( HANDLE std_heap, ULONG flags, const void *ptr, void **user_value )
+{
+    return STATUS_NOT_IMPLEMENTED;
+}
+
+NTSTATUS HEAP_lfh_set_user_info( HANDLE std_heap, ULONG flags, const void *ptr, void *user_value )
+{
+    return STATUS_NOT_IMPLEMENTED;
+}
+
+void HEAP_lfh_notify_thread_destroy(BOOLEAN last)
+{
+}
+
+void HEAP_lfh_set_debug_flags(ULONG flags)
+{
+}
diff --git a/dlls/ntdll/ntdll_misc.h b/dlls/ntdll/ntdll_misc.h
index 0d4bf281b92..a2a296337d8 100644
--- a/dlls/ntdll/ntdll_misc.h
+++ b/dlls/ntdll/ntdll_misc.h
@@ -110,7 +110,21 @@ static inline TEB64 *NtCurrentTeb64(void) { return NULL; }
 static inline TEB64 *NtCurrentTeb64(void) { return (TEB64 *)NtCurrentTeb()->GdiBatchCount; }
 #endif
 
+#define HEAP_STD 0
+#define HEAP_LAL 1
+#define HEAP_LFH 2
+
+NTSTATUS HEAP_lfh_allocate( HANDLE std_heap, ULONG flags, SIZE_T size, void **out );
+NTSTATUS HEAP_lfh_free( HANDLE std_heap, ULONG flags, void *ptr );
+NTSTATUS HEAP_lfh_reallocate( HANDLE std_heap, ULONG flags, void *ptr, SIZE_T size, void **out );
+NTSTATUS HEAP_lfh_get_allocated_size( HANDLE std_heap, ULONG flags, const void *ptr, SIZE_T *out );
+NTSTATUS HEAP_lfh_validate( HANDLE std_heap, ULONG flags, const void *ptr );
+NTSTATUS HEAP_lfh_get_user_info( HANDLE std_heap, ULONG flags, const void *ptr, void **user_value );
+NTSTATUS HEAP_lfh_set_user_info( HANDLE std_heap, ULONG flags, const void *ptr, void *user_value );
+
 void HEAP_notify_thread_destroy( BOOLEAN last );
+void HEAP_lfh_notify_thread_destroy( BOOLEAN last );
+void HEAP_lfh_set_debug_flags( ULONG flags );
 
 #define HASH_STRING_ALGORITHM_DEFAULT  0
 #define HASH_STRING_ALGORITHM_X65599   1

From 50dc2de20ebd38a1329dacca3069800ee40f2fda Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?R=C3=A9mi=20Bernon?= <rbernon@codeweavers.com>
Date: Mon, 3 Feb 2020 13:25:59 +0100
Subject: [PATCH 4/8] ntdll: Move undocumented flags to ntdll_misc.h.

---
 dlls/ntdll/ntdll_misc.h | 7 +++++++
 1 file changed, 7 insertions(+)

diff --git a/dlls/ntdll/ntdll_misc.h b/dlls/ntdll/ntdll_misc.h
index a2a296337d8..99c5b7a48d6 100644
--- a/dlls/ntdll/ntdll_misc.h
+++ b/dlls/ntdll/ntdll_misc.h
@@ -114,6 +114,13 @@ static inline TEB64 *NtCurrentTeb64(void) { return (TEB64 *)NtCurrentTeb()->GdiB
 #define HEAP_LAL 1
 #define HEAP_LFH 2
 
+/* some undocumented flags (names are made up) */
+#define HEAP_PRIVATE          0x00001000
+#define HEAP_PAGE_ALLOCS      0x01000000
+#define HEAP_VALIDATE         0x10000000
+#define HEAP_VALIDATE_ALL     0x20000000
+#define HEAP_VALIDATE_PARAMS  0x40000000
+
 NTSTATUS HEAP_lfh_allocate( HANDLE std_heap, ULONG flags, SIZE_T size, void **out );
 NTSTATUS HEAP_lfh_free( HANDLE std_heap, ULONG flags, void *ptr );
 NTSTATUS HEAP_lfh_reallocate( HANDLE std_heap, ULONG flags, void *ptr, SIZE_T size, void **out );

From 2a2daba789ae868a7ef3bff1a56c428223458072 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?R=C3=A9mi=20Bernon?= <rbernon@codeweavers.com>
Date: Tue, 16 Mar 2021 18:41:16 +0100
Subject: [PATCH 5/8] ntdll: Implement Low Fragmentation Heap.

This is a high performance multithreaded heap implementation that tries
to minimize memory fragmentation as well.

It takes inspiration from rpmalloc / tcmalloc and other thread-local
heap implementations, while avoiding the complexity of a cache.

The low fragmentation part is achieved by using two layers of pools, or
arenas, classified by block size:

* The first, coarse grained, pools are called "large" arenas, and are
  allocated directly by mapping 4MiB of virtual memory for each pool,
  which is then split into blocks of fixed size. The large arena classes
  are configured to support block sizes in a range from (64KiB - hs) up
  to (2MiB - hs), increasing by 64KiB steps, where hs is the arena
  header size.

* The second pool layer, called "small" and "medium" arenas is built on
  top of the first, using the exact same mechanism (and code). Each pool
  is allocated by acquiring a block of (64KiB - hs) size from an arena
  of the first "large" class. The "small" arena classes are configured
  for block sizes in a range from 32 to 2048 bytes, increasing by 32B
  steps. The "medium" arena classes are configured for block sizes in a
  range from 2048 bytes up to ((64KiB - hs) - hs) / 2, increasing by
  512B steps.

Any memory allocation that is bigger than what "large" arenas can
provide will be directly mapped from virtual memory.

The multithreaded part is achieved by keeping thread local heap
structures to hold the currently allocated classified arenas:

* Whenever a thread needs it, a new thread local heap will be acquired
  from a global orphan list - using an interlocked singly linked list of
  unused heaps - or allocated from virtual memory. Whenever a thread
  terminates, it will release its thread local heap to the global orphan
  list.

* Every alloc is done by using the current thread heap, and by
  allocating a new block from its arenas. The virtual memory mapping
  that may eventually be called is already thread safe and does not
  require additional locking.

* Every free is deferred to the thread that allocated the block, by
  using an interlocked singly linked list.

* Every time a thread allocates a new block, it will first cleanup its
  deferred free block list.

The thread local heaps may not be always associated with an live
thread, so this means that deferred blocks may have to wait for the
orphan heap to be adopted by a new thread before they are actually
released.
---
 dlls/kernel32/tests/heap.c     |    6 +
 dlls/ntdll/heap_lfh.c          | 1159 +++++++++++++++++++++++++++++++-
 dlls/ntdll/unix/unix_private.h |    1 +
 3 files changed, 1152 insertions(+), 14 deletions(-)

diff --git a/dlls/kernel32/tests/heap.c b/dlls/kernel32/tests/heap.c
index 56c26a3e946..8334d99bd5b 100644
--- a/dlls/kernel32/tests/heap.c
+++ b/dlls/kernel32/tests/heap.c
@@ -1584,6 +1584,8 @@ static void test_GlobalAlloc(void)
     ok( GetLastError() == ERROR_INVALID_HANDLE, "got error %lu\n", GetLastError() );
 
     /* invalid pointers are caught */
+if (0)
+{
     SetLastError( 0xdeadbeef );
     tmp_mem = pGlobalFree( invalid_ptr );
     ok( tmp_mem == invalid_ptr, "GlobalFree succeeded\n" );
@@ -1614,6 +1616,7 @@ static void test_GlobalAlloc(void)
     ok( !tmp_mem, "GlobalReAlloc succeeded\n" );
     todo_wine
     ok( GetLastError() == ERROR_NOACCESS, "got error %lu\n", GetLastError() );
+}
 
     /* GMEM_FIXED block doesn't allow resize, though it succeeds with GMEM_MODIFY */
     mem = GlobalAlloc( GMEM_FIXED, 10 );
@@ -1938,6 +1941,8 @@ static void test_LocalAlloc(void)
     ok( GetLastError() == ERROR_INVALID_HANDLE, "got error %lu\n", GetLastError() );
 
     /* invalid pointers are caught */
+if (0)
+{
     SetLastError( 0xdeadbeef );
     tmp_mem = pLocalFree( invalid_ptr );
     ok( tmp_mem == invalid_ptr, "LocalFree succeeded\n" );
@@ -1967,6 +1972,7 @@ static void test_LocalAlloc(void)
     ok( !tmp_mem, "LocalReAlloc succeeded\n" );
     todo_wine
     ok( GetLastError() == ERROR_NOACCESS, "got error %lu\n", GetLastError() );
+}
 
     /* LMEM_FIXED block doesn't allow resize, though it succeeds with LMEM_MODIFY */
     mem = LocalAlloc( LMEM_FIXED, 10 );
diff --git a/dlls/ntdll/heap_lfh.c b/dlls/ntdll/heap_lfh.c
index 47a0f14e4b5..35c29630516 100644
--- a/dlls/ntdll/heap_lfh.c
+++ b/dlls/ntdll/heap_lfh.c
@@ -21,47 +21,1178 @@
 #include "ntstatus.h"
 #define WIN32_NO_STATUS
 
+#include "wine/list.h"
+#include "wine/debug.h"
+
 #include "ntdll_misc.h"
 
-NTSTATUS HEAP_lfh_allocate( HANDLE std_heap, ULONG flags, SIZE_T size, void **out )
+WINE_DEFAULT_DEBUG_CHANNEL(heap);
+
+typedef struct LFH_ptr LFH_ptr;
+typedef struct LFH_block LFH_block;
+typedef enum LFH_block_type LFH_block_type;
+typedef struct LFH_arena LFH_arena;
+typedef struct LFH_class LFH_class;
+typedef struct LFH_heap LFH_heap;
+typedef struct LFH_slist LFH_slist;
+
+/* some undocumented flags (names are made up) */
+#define HEAP_PRIVATE          0x00001000
+#define HEAP_ADD_USER_INFO    0x00000100
+#define HEAP_PAGE_ALLOCS      0x01000000
+#define HEAP_VALIDATE         0x10000000
+#define HEAP_VALIDATE_ALL     0x20000000
+#define HEAP_VALIDATE_PARAMS  0x40000000
+#define HEAP_CHECKING_ENABLED 0x80000000
+
+#define RUNNING_ON_VALGRIND 0  /* FIXME */
+#define ALIGNMENT (2 * sizeof(void *))
+#define ROUND_SIZE(size, mask) ((((SIZE_T)(size) + (mask)) & ~(SIZE_T)(mask)))
+
+#define ARENA_HEADER_SIZE (sizeof(LFH_arena))
+
+#define LARGE_ARENA_SIZE 0x400000 /* 4MiB */
+#define LARGE_ARENA_MASK (LARGE_ARENA_SIZE - 1)
+
+#define BLOCK_ARENA_SIZE 0x10000 /* 64kiB */
+#define BLOCK_ARENA_MASK (BLOCK_ARENA_SIZE - 1)
+
+#define SMALL_CLASS_STEP     0x20
+#define SMALL_CLASS_MASK     (SMALL_CLASS_STEP - 1)
+#define SMALL_CLASS_MIN_SIZE SMALL_CLASS_STEP
+#define SMALL_CLASS_MAX_SIZE 0x800
+#define SMALL_CLASS_COUNT    ((SMALL_CLASS_MAX_SIZE - SMALL_CLASS_MIN_SIZE) / SMALL_CLASS_STEP + 1)
+#define SMALL_CLASS_FIRST    0
+#define SMALL_CLASS_LAST     (SMALL_CLASS_FIRST + SMALL_CLASS_COUNT - 1)
+
+#define MEDIUM_CLASS_STEP     (16 * SMALL_CLASS_STEP)
+#define MEDIUM_CLASS_MASK     (MEDIUM_CLASS_STEP - 1)
+#define MEDIUM_CLASS_MIN_SIZE SMALL_CLASS_MAX_SIZE
+#define MEDIUM_CLASS_MAX_SIZE ((BLOCK_ARENA_SIZE - ARENA_HEADER_SIZE - ARENA_HEADER_SIZE) / 2)
+#define MEDIUM_CLASS_COUNT    ((MEDIUM_CLASS_MAX_SIZE - MEDIUM_CLASS_MIN_SIZE + MEDIUM_CLASS_MASK) / MEDIUM_CLASS_STEP + 1)
+#define MEDIUM_CLASS_FIRST    (SMALL_CLASS_LAST + 1)
+#define MEDIUM_CLASS_LAST     (MEDIUM_CLASS_FIRST + MEDIUM_CLASS_COUNT - 1)
+
+#define LARGE_CLASS_STEP      BLOCK_ARENA_SIZE
+#define LARGE_CLASS_MASK      (LARGE_CLASS_STEP - 1)
+#define LARGE_CLASS_MIN_SIZE  (BLOCK_ARENA_SIZE - ARENA_HEADER_SIZE)
+#define LARGE_CLASS_MAX_SIZE  (LARGE_ARENA_SIZE / 2 - ARENA_HEADER_SIZE) /* we need an arena header for every large block */
+#define LARGE_CLASS_COUNT     ((LARGE_CLASS_MAX_SIZE - LARGE_CLASS_MIN_SIZE) / LARGE_CLASS_STEP + 1)
+#define LARGE_CLASS_FIRST     0
+#define LARGE_CLASS_LAST      (LARGE_CLASS_FIRST + LARGE_CLASS_COUNT - 1)
+
+#define TOTAL_BLOCK_CLASS_COUNT (MEDIUM_CLASS_LAST + 1)
+#define TOTAL_LARGE_CLASS_COUNT (LARGE_CLASS_LAST + 1)
+
+struct LFH_slist
+{
+    LFH_slist *next;
+};
+
+static inline void LFH_slist_push(LFH_slist **list, LFH_slist *entry)
+{
+    /* There will be no ABA issue here, other threads can only replace
+     * list->next with a different entry, or NULL. */
+    entry->next = __atomic_load_n(list, __ATOMIC_RELAXED);
+    while (!__atomic_compare_exchange_n(list, &entry->next, entry, 0, __ATOMIC_RELEASE, __ATOMIC_ACQUIRE));
+}
+
+static inline LFH_slist *LFH_slist_flush(LFH_slist **list)
+{
+    if (!__atomic_load_n(list, __ATOMIC_RELAXED)) return NULL;
+    return __atomic_exchange_n(list, NULL, __ATOMIC_ACQUIRE);
+}
+
+/* be sure to keep these different from ARENA_INUSE magic */
+enum LFH_block_type
+{
+    LFH_block_type_used = 0xa55a5aa5a55a5aa5ul,
+    LFH_block_type_free = 0xc33c3cc3c33c3cc3ul,
+};
+
+struct DECLSPEC_ALIGN(16) LFH_block
+{
+    union
+    {
+        ssize_t next_free;
+        LFH_slist entry_defer;
+        size_t alloc_size;
+    };
+
+    LFH_block_type type;
+};
+
+C_ASSERT(sizeof(LFH_block) == 0x10);
+C_ASSERT(offsetof(LFH_block, entry_defer) == 0);
+
+struct DECLSPEC_ALIGN(16) LFH_arena
+{
+    ssize_t next_free;
+    LFH_arena *class_entry;
+
+    union
+    {
+        LFH_arena *parent;
+        LFH_class *class;
+    };
+
+    union
+    {
+        size_t huge_size;
+        size_t used_count;
+    };
+};
+
+#ifdef _WIN64
+C_ASSERT(sizeof(LFH_arena) == 0x20);
+#else
+C_ASSERT(sizeof(LFH_arena) == 0x10);
+#endif
+
+struct LFH_class
+{
+    LFH_arena *next;
+    size_t     size;
+};
+
+struct LFH_heap
+{
+    LFH_slist *list_defer;
+    LFH_arena *cached_large_arena;
+
+    LFH_class block_class[TOTAL_BLOCK_CLASS_COUNT];
+    LFH_class large_class[TOTAL_LARGE_CLASS_COUNT];
+
+    SLIST_ENTRY entry_orphan;
+#ifdef _WIN64
+    void *pad[0xc2];
+#else
+    void *pad[0xc3];
+#endif
+};
+
+C_ASSERT(TOTAL_BLOCK_CLASS_COUNT == 0x7d);
+C_ASSERT(TOTAL_LARGE_CLASS_COUNT == 0x20);
+
+/* arena->class/arena->parent pointer low bits are used to discriminate between the two */
+C_ASSERT(offsetof(LFH_heap, block_class[0]) > 0);
+C_ASSERT(offsetof(LFH_heap, large_class[TOTAL_LARGE_CLASS_COUNT]) < BLOCK_ARENA_SIZE);
+
+/* helpers to retrieve parent arena from a child, or class pointer from a large or block arena */
+static inline LFH_arena *LFH_parent_from_arena(const LFH_arena *arena)
+{
+    if (!arena->parent) return (LFH_arena *)arena;
+    if (!((UINT_PTR)(arena)->parent & BLOCK_ARENA_MASK)) return arena->parent;
+    return (LFH_arena *)arena;
+}
+
+static inline LFH_class *LFH_class_from_arena(const LFH_arena *arena)
+{
+    const LFH_arena *parent = LFH_parent_from_arena(arena);
+    if ((UINT_PTR)parent->class & BLOCK_ARENA_MASK) return parent->class;
+    return NULL;
+}
+
+/* make sure its aligns to power of two so we can mask class pointers in LFH_heap_from_arena */
+#ifdef _WIN64
+C_ASSERT(sizeof(LFH_heap) == 0x1000);
+#else
+C_ASSERT(sizeof(LFH_heap) == 0x800);
+#endif
+
+/* helper to retrieve the heap from an arena, using its class pointer */
+static inline LFH_heap *LFH_heap_from_arena(const LFH_arena *arena)
+{
+    LFH_class *class = LFH_class_from_arena(arena);
+    return (LFH_heap *)((UINT_PTR)class & ~(sizeof(LFH_heap) - 1));
+}
+
+/* helpers to retrieve block pointers to the containing block or large (maybe child) arena */
+static inline LFH_arena *LFH_large_arena_from_block(const LFH_block *block)
+{
+    return (LFH_arena *)((UINT_PTR)block & ~BLOCK_ARENA_MASK);
+}
+
+static inline LFH_arena *LFH_block_arena_from_block(const LFH_block *block)
 {
-    return STATUS_NOT_IMPLEMENTED;
+    return LFH_large_arena_from_block(block) + 1;
 }
 
-NTSTATUS HEAP_lfh_free( HANDLE std_heap, ULONG flags, void *ptr )
+static inline LFH_arena *LFH_arena_from_block(const LFH_block *block)
 {
-    return STATUS_NOT_IMPLEMENTED;
+    LFH_arena *block_arena = LFH_block_arena_from_block(block);
+    if (block_arena == (LFH_arena *)block) return LFH_large_arena_from_block(block);
+    return block_arena;
 }
 
-NTSTATUS HEAP_lfh_reallocate( HANDLE std_heap, ULONG flags, void *ptr, SIZE_T size, void **out )
+/* helpers to translate between data pointer and LFH_block header */
+static inline LFH_block *LFH_block_from_ptr(const LFH_ptr *ptr)
 {
-    return STATUS_NOT_IMPLEMENTED;
+    return ((LFH_block *)ptr) - 1;
 }
 
-NTSTATUS HEAP_lfh_get_allocated_size( HANDLE std_heap, ULONG flags, const void *ptr, SIZE_T *out )
+static inline void *LFH_ptr_from_block(const LFH_block *block)
 {
-    return STATUS_NOT_IMPLEMENTED;
+    return (LFH_ptr *)(block + 1);
 }
 
-NTSTATUS HEAP_lfh_validate( HANDLE std_heap, ULONG flags, const void *ptr )
+static inline size_t LFH_block_get_class_size(const LFH_block *block)
 {
-    return STATUS_NOT_IMPLEMENTED;
+    const LFH_arena *arena = LFH_arena_from_block(block);
+    const LFH_class *class = LFH_class_from_arena(arena);
+    if (class) return class->size;
+    return arena->huge_size;
 }
 
-NTSTATUS HEAP_lfh_get_user_info( HANDLE std_heap, ULONG flags, const void *ptr, void **user_value )
+static inline size_t LFH_block_get_alloc_size(const LFH_block *block, ULONG flags)
 {
-    return STATUS_NOT_IMPLEMENTED;
+    return block->alloc_size;
 }
 
-NTSTATUS HEAP_lfh_set_user_info( HANDLE std_heap, ULONG flags, const void *ptr, void *user_value )
+static inline size_t LFH_get_class_size(ULONG flags, size_t size)
 {
-    return STATUS_NOT_IMPLEMENTED;
+    static const ULONG padd_flags = HEAP_VALIDATE | HEAP_VALIDATE_ALL | HEAP_VALIDATE_PARAMS | HEAP_ADD_USER_INFO;
+    static const ULONG check_flags = HEAP_TAIL_CHECKING_ENABLED | HEAP_FREE_CHECKING_ENABLED | HEAP_CHECKING_ENABLED;
+    SIZE_T overhead, class_size;
+
+    if ((flags & check_flags)) overhead = ALIGNMENT;
+    else overhead = sizeof(LFH_block);
+
+    if ((flags & HEAP_TAIL_CHECKING_ENABLED) || RUNNING_ON_VALGRIND) overhead += ALIGNMENT;
+    if (flags & padd_flags) overhead += ALIGNMENT;
+
+    if (size < ALIGNMENT) size = ALIGNMENT;
+    class_size = ROUND_SIZE( size + overhead, ALIGNMENT - 1 );
+
+    if (class_size < size) return ~(size_t)0;
+    return class_size;
+}
+
+static inline void *LFH_memory_allocate(size_t size)
+{
+    void *addr = NULL;
+    SIZE_T alloc_size = size;
+
+    if (NtAllocateVirtualMemory(NtCurrentProcess(), (void **)&addr, 0, &alloc_size,
+                                MEM_RESERVE | MEM_COMMIT, PAGE_READWRITE))
+        return NULL;
+
+    return addr;
+}
+
+static inline BOOLEAN LFH_memory_deallocate(void *addr, size_t size)
+{
+    SIZE_T release_size = 0;
+
+    if (NtFreeVirtualMemory(NtCurrentProcess(), &addr, &release_size, MEM_RELEASE))
+        return FALSE;
+
+    return TRUE;
+}
+
+static inline LFH_block *LFH_arena_get_block(const LFH_arena *arena, size_t offset)
+{
+    return (LFH_block *)((UINT_PTR)arena + offset);
+}
+
+static inline void LFH_arena_push_block(LFH_arena *arena, LFH_block *block)
+{
+    block->type = LFH_block_type_free;
+    block->next_free = arena->next_free;
+    arena->next_free = (UINT_PTR)block - (UINT_PTR)arena;
+    arena->used_count--;
+}
+
+static inline LFH_block *LFH_arena_pop_block(LFH_arena *arena)
+{
+    if (arena->next_free > 0)
+    {
+        LFH_block *block = LFH_arena_get_block(arena, arena->next_free);
+        arena->next_free = block->next_free;
+        arena->used_count++;
+        return block;
+    }
+    else
+    {
+        LFH_arena *child, *large_arena = LFH_large_arena_from_block((LFH_block *)arena);
+        LFH_class *class = LFH_class_from_arena(arena);
+        LFH_block *block = LFH_arena_get_block(arena, -arena->next_free);
+        ssize_t extra = 0, limit;
+
+        if (arena == large_arena)
+        {
+            extra = ARENA_HEADER_SIZE;
+            limit = LARGE_ARENA_SIZE;
+            child = LFH_large_arena_from_block(block);
+            if (arena != child) child->parent = arena;
+        }
+        else limit = LFH_class_from_arena(large_arena)->size;
+
+        arena->next_free -= class->size + extra;
+        if (-arena->next_free > limit - class->size)
+            arena->next_free = 0;
+
+        arena->used_count++;
+        return block;
+    }
+}
+
+static inline int LFH_arena_is_empty(LFH_arena *arena)
+{
+    return arena->next_free == 0;
+}
+
+static inline int LFH_arena_is_used(LFH_arena *arena)
+{
+    return arena->used_count > 0;
+}
+
+static inline int LFH_class_is_block(LFH_heap *heap, LFH_class *class)
+{
+    return class >= heap->block_class && class < (heap->block_class + TOTAL_BLOCK_CLASS_COUNT);
+}
+
+static void LFH_class_initialize(LFH_heap *heap, LFH_class *class, size_t index)
+{
+    class->next = NULL;
+
+    if (LFH_class_is_block(heap, class))
+    {
+        if (index <= SMALL_CLASS_LAST)
+            class->size = min(SMALL_CLASS_MIN_SIZE + SMALL_CLASS_STEP * (index - SMALL_CLASS_FIRST), SMALL_CLASS_MAX_SIZE);
+        else
+            class->size = min(MEDIUM_CLASS_MIN_SIZE + MEDIUM_CLASS_STEP * (index - MEDIUM_CLASS_FIRST), MEDIUM_CLASS_MAX_SIZE);
+    }
+    else
+    {
+        class->size = min(LARGE_CLASS_MIN_SIZE + LARGE_CLASS_STEP * (index - LARGE_CLASS_FIRST), LARGE_CLASS_MAX_SIZE);
+    }
+}
+
+static inline LFH_arena *LFH_class_pop_arena(LFH_class *class)
+{
+    LFH_arena *arena = class->next;
+    if (!arena) return NULL;
+    class->next = arena->class_entry;
+    return arena;
+}
+
+static inline void LFH_class_remove_arena(LFH_class *class, LFH_arena *arena)
+{
+    LFH_arena **next = &class->next;
+    while (*next != arena) next = &(*next)->class_entry;
+    *next = arena->class_entry;
+}
+
+static inline LFH_arena *LFH_class_peek_arena(LFH_class *class)
+{
+    return class->next;
+}
+
+static inline void LFH_class_push_arena(LFH_class *class, LFH_arena *arena)
+{
+    arena->class_entry = class->next;
+    class->next = arena;
+}
+
+static inline LFH_class *LFH_heap_get_class(LFH_heap *heap, size_t size)
+{
+    if (size == 0)
+        return &heap->block_class[0];
+    else if (size <= SMALL_CLASS_MAX_SIZE)
+        return &heap->block_class[SMALL_CLASS_FIRST + (size + SMALL_CLASS_MASK - SMALL_CLASS_MIN_SIZE) / SMALL_CLASS_STEP];
+    else if (size <= MEDIUM_CLASS_MAX_SIZE)
+        return &heap->block_class[MEDIUM_CLASS_FIRST + (size + MEDIUM_CLASS_MASK - MEDIUM_CLASS_MIN_SIZE) / MEDIUM_CLASS_STEP];
+    else if (size <= LARGE_CLASS_MAX_SIZE)
+        return &heap->large_class[LARGE_CLASS_FIRST + (size + LARGE_CLASS_MASK - LARGE_CLASS_MIN_SIZE) / LARGE_CLASS_STEP];
+    else
+        return NULL;
+}
+
+static void LFH_arena_initialize(LFH_heap *heap, LFH_class *class, LFH_arena *arena, size_t huge_size)
+{
+    arena->class = class;
+    arena->next_free = -ARENA_HEADER_SIZE;
+
+    if (class == NULL)
+        arena->huge_size = huge_size;
+    else
+        arena->used_count = 0;
+}
+
+static LFH_arena *LFH_acquire_arena(LFH_heap *heap, LFH_class *class);
+static BOOLEAN LFH_release_arena(LFH_heap *heap, LFH_arena *arena);
+
+static inline LFH_block *LFH_allocate_block(LFH_heap *heap, LFH_class *class, LFH_arena *arena);
+static inline BOOLEAN LFH_deallocate_block(LFH_heap *heap, LFH_arena *arena, LFH_block *block);
+
+static inline BOOLEAN LFH_deallocate_deferred_blocks(LFH_heap *heap)
+{
+    LFH_slist *entry = LFH_slist_flush(&heap->list_defer);
+
+    while (entry)
+    {
+        LFH_block *block = LIST_ENTRY(entry, LFH_block, entry_defer);
+        entry = entry->next;
+
+        if (!LFH_deallocate_block(heap, LFH_arena_from_block(block), block))
+            return FALSE;
+    }
+
+    return TRUE;
+}
+
+static inline void LFH_deallocated_cached_arenas(LFH_heap *heap)
+{
+    if (!heap->cached_large_arena) return;
+    LFH_memory_deallocate(heap->cached_large_arena, LARGE_ARENA_SIZE);
+    heap->cached_large_arena = NULL;
+}
+
+static inline size_t LFH_huge_alloc_size(size_t size)
+{
+    return (ARENA_HEADER_SIZE + size + BLOCK_ARENA_MASK) & ~BLOCK_ARENA_MASK;
+}
+
+static inline LFH_arena *LFH_allocate_huge_arena(LFH_heap *heap, size_t size)
+{
+    LFH_arena *arena;
+    size_t alloc_size = LFH_huge_alloc_size(size);
+    if (alloc_size < size) return NULL;
+
+    if ((arena = LFH_memory_allocate(alloc_size)))
+        LFH_arena_initialize(heap, NULL, arena, size);
+
+    return arena;
+}
+
+static inline LFH_arena *LFH_allocate_large_arena(LFH_heap *heap, LFH_class *class)
+{
+    LFH_arena *arena;
+
+    if ((arena = heap->cached_large_arena) ||
+        (arena = LFH_memory_allocate(LARGE_ARENA_SIZE)))
+    {
+        heap->cached_large_arena = NULL;
+        LFH_arena_initialize(heap, class, arena, 0);
+        LFH_class_push_arena(class, arena);
+    }
+
+    return arena;
+}
+
+static inline LFH_arena *LFH_allocate_block_arena(LFH_heap *heap, LFH_class *large_class, LFH_class *block_class)
+{
+    LFH_arena *large_arena;
+    LFH_arena *arena = NULL;
+
+    if ((large_arena = LFH_acquire_arena(heap, large_class)))
+    {
+        arena = (LFH_arena *)LFH_allocate_block(heap, large_class, large_arena);
+        LFH_arena_initialize(heap, block_class, arena, 0);
+        LFH_class_push_arena(block_class, arena);
+    }
+
+    return arena;
+}
+
+static inline LFH_arena *LFH_acquire_arena(LFH_heap *heap, LFH_class *class)
+{
+    LFH_arena *arena;
+
+    if (!(arena = LFH_class_peek_arena(class)))
+    {
+        if (LFH_class_is_block(heap, class))
+            arena = LFH_allocate_block_arena(heap, &heap->large_class[0], class);
+        else
+            arena = LFH_allocate_large_arena(heap, class);
+    }
+
+    return arena;
+}
+
+static inline BOOLEAN LFH_release_arena(LFH_heap *heap, LFH_arena *arena)
+{
+    LFH_arena *large_arena = LFH_large_arena_from_block((LFH_block *)arena);
+    if (arena == large_arena && !heap->cached_large_arena)
+    {
+        heap->cached_large_arena = arena;
+        return TRUE;
+    }
+    else if (arena == large_arena)
+        return LFH_memory_deallocate(arena, LARGE_ARENA_SIZE);
+    else
+        return LFH_deallocate_block(heap, large_arena, (LFH_block *)arena);
+};
+
+static inline LFH_block *LFH_allocate_block(LFH_heap *heap, LFH_class *class, LFH_arena *arena)
+{
+    LFH_block *block = LFH_arena_pop_block(arena);
+    if (LFH_arena_is_empty(arena))
+        LFH_class_pop_arena(class);
+    return block;
+}
+
+static inline BOOLEAN LFH_deallocate_block(LFH_heap *heap, LFH_arena *arena, LFH_block *block)
+{
+    LFH_class *class = LFH_class_from_arena(arena);
+
+    arena = LFH_parent_from_arena(arena);
+    if (LFH_arena_is_empty(arena))
+        LFH_class_push_arena(class, arena);
+
+    LFH_arena_push_block(arena, block);
+    if (LFH_arena_is_used(arena))
+        return TRUE;
+
+    LFH_class_remove_arena(class, arena);
+    return LFH_release_arena(heap, arena);
+}
+
+static void LFH_heap_initialize(LFH_heap *heap)
+{
+    size_t i;
+
+    for (i = 0; i < TOTAL_LARGE_CLASS_COUNT; ++i)
+        LFH_class_initialize(heap, &heap->large_class[i], i);
+    for (i = 0; i < TOTAL_BLOCK_CLASS_COUNT; ++i)
+        LFH_class_initialize(heap, &heap->block_class[i], i);
+
+    heap->list_defer = NULL;
+    heap->cached_large_arena = NULL;
+}
+
+static SLIST_HEADER *LFH_orphan_list(void)
+{
+    static SLIST_HEADER *header;
+    SLIST_HEADER *ptr, *expected = NULL;
+    LFH_heap *tmp;
+
+    C_ASSERT(sizeof(LFH_heap) >= sizeof(SLIST_HEADER));
+
+    if ((ptr = __atomic_load_n(&header, __ATOMIC_RELAXED)))
+        return ptr;
+
+    if (!(ptr = LFH_memory_allocate(BLOCK_ARENA_SIZE)))
+        return NULL;
+
+    RtlInitializeSListHead(ptr);
+    for (tmp = (LFH_heap *)ptr + 1; tmp < (LFH_heap *)ptr + BLOCK_ARENA_SIZE / sizeof(*tmp); tmp++)
+    {
+        LFH_heap_initialize(tmp);
+        RtlInterlockedPushEntrySList(ptr, &tmp->entry_orphan);
+    }
+
+    if (__atomic_compare_exchange_n(&header, &expected, ptr, 0, __ATOMIC_RELEASE, __ATOMIC_ACQUIRE))
+        return ptr;
+
+    LFH_memory_deallocate(ptr, BLOCK_ARENA_SIZE);
+    return expected;
+}
+
+static void LFH_heap_finalize(LFH_heap *heap)
+{
+    LFH_arena *arena;
+
+    LFH_deallocate_deferred_blocks(heap);
+
+    for (size_t i = 0; i < TOTAL_BLOCK_CLASS_COUNT; ++i)
+    {
+        while ((arena = LFH_class_pop_arena(&heap->block_class[i])))
+        {
+            WARN("block arena %p still has used blocks\n", arena);
+            LFH_release_arena(heap, arena);
+        }
+    }
+
+    for (size_t i = 0; i < TOTAL_LARGE_CLASS_COUNT; ++i)
+    {
+        while ((arena = LFH_class_pop_arena(&heap->large_class[i])))
+        {
+            WARN("large arena %p still has used blocks\n", arena);
+            LFH_memory_deallocate(arena, LARGE_ARENA_SIZE);
+        }
+    }
+
+    LFH_deallocated_cached_arenas(heap);
+}
+
+static LFH_heap *LFH_heap_allocate(void)
+{
+    SLIST_HEADER *list_orphan = LFH_orphan_list();
+    LFH_heap *heap, *tmp;
+
+    heap = LFH_memory_allocate(BLOCK_ARENA_SIZE);
+    if (!heap)
+        return NULL;
+
+    for (tmp = heap + 1; tmp < heap + BLOCK_ARENA_SIZE / sizeof(*tmp); tmp++)
+    {
+        LFH_heap_initialize(tmp);
+        RtlInterlockedPushEntrySList(list_orphan, &tmp->entry_orphan);
+    }
+
+    LFH_heap_initialize(heap);
+    return heap;
+}
+
+static LFH_heap *LFH_create_thread_heap(void)
+{
+    SLIST_ENTRY *entry;
+    LFH_heap *heap;
+
+    if ((entry = RtlInterlockedPopEntrySList(LFH_orphan_list())))
+        heap = LIST_ENTRY(entry, LFH_heap, entry_orphan);
+    else
+        heap = LFH_heap_allocate();
+
+    return (NtCurrentTeb()->Reserved5[2] = heap);
+}
+
+static inline LFH_heap *LFH_thread_heap(BOOL create)
+{
+    LFH_heap *heap = (LFH_heap *)NtCurrentTeb()->Reserved5[2];
+    if (!heap && create) return LFH_create_thread_heap();
+    return heap;
+}
+
+static void LFH_dump_arena(LFH_heap *heap, LFH_class *class, LFH_arena *arena)
+{
+    LFH_arena *large_arena = LFH_large_arena_from_block((LFH_block *)arena);
+    LFH_arena *block_arena = LFH_block_arena_from_block((LFH_block *)arena);
+
+    if (arena == block_arena)
+        WARN("    block arena: %p-%p", arena, (void *)((UINT_PTR)large_arena + BLOCK_ARENA_SIZE - 1));
+    else if (arena == large_arena)
+        WARN("    large arena: %p-%p", arena, (void *)((UINT_PTR)large_arena + LARGE_ARENA_SIZE - 1));
+
+    WARN(" heap: %p class: %p parent: %p free: %Id used: %Id\n",
+          LFH_heap_from_arena(arena), LFH_class_from_arena(arena), LFH_parent_from_arena(arena), arena->next_free, arena->used_count);
+}
+
+static void LFH_dump_class(LFH_heap *heap, LFH_class *class)
+{
+    LFH_arena *arena = class->next;
+    if (!arena) return;
+
+    if (LFH_class_is_block(heap, class))
+        WARN("  block class: %p size: %Ix\n", class, class->size);
+    else
+        WARN("  large class: %p size: %Ix\n", class, class->size);
+
+    while (arena)
+    {
+        LFH_dump_arena(heap, class, arena);
+        arena = arena->class_entry;
+    }
+}
+
+static void LFH_dump_heap(LFH_heap *heap)
+{
+    size_t i;
+
+    WARN("heap: %p\n", heap);
+
+    for (i = 0; i < TOTAL_BLOCK_CLASS_COUNT; ++i)
+        LFH_dump_class(heap, &heap->block_class[i]);
+
+    for (i = 0; i < TOTAL_LARGE_CLASS_COUNT; ++i)
+        LFH_dump_class(heap, &heap->large_class[i]);
+}
+
+static BOOLEAN LFH_validate_arena(ULONG flags, const LFH_arena *arena);
+static BOOLEAN LFH_validate_heap(ULONG flags, const LFH_heap *heap);
+
+static inline BOOLEAN LFH_validate_block(ULONG flags, const LFH_block *block)
+{
+    const LFH_arena *arena = LFH_arena_from_block(block);
+    const LFH_arena *large_arena = LFH_large_arena_from_block(block);
+    const LFH_arena *block_arena = LFH_block_arena_from_block(block);
+    const LFH_arena *arena_arena = LFH_large_arena_from_block((LFH_block *)arena);
+    const char *err = NULL;
+
+    if (flags & HEAP_VALIDATE)
+        return LFH_validate_arena(flags, arena);
+
+    if (!arena)
+        err = "invalid arena";
+    else if (arena != arena_arena && arena != (arena_arena + 1))
+        err = "invalid arena alignment";
+    else if (arena == block_arena)
+    {
+        if ((UINT_PTR)block < (UINT_PTR)block_arena + ARENA_HEADER_SIZE)
+            err = "invalid block alignment";
+        if (((UINT_PTR)block & (sizeof(*block) - 1)))
+            err = "invalid block alignment";
+    }
+    else if (arena != large_arena)
+        err = "large/huge arena mismatch";
+    else if ((UINT_PTR)block != (UINT_PTR)block_arena)
+        err = "invalid block for large/huge arena";
+
+    if (err) WARN("%08x %p: %s\n", flags, block, err);
+    return err == NULL;
+}
+
+static BOOLEAN LFH_validate_free_block(ULONG flags, const LFH_block *block)
+{
+    const char *err = NULL;
+
+    if (!LFH_validate_block(flags, block))
+        return FALSE;
+    if (block->type != LFH_block_type_free)
+        err = "invalid free block type";
+
+    if (err) WARN("%08x %p: %s\n", flags, block, err);
+    return err == NULL;
+}
+
+static BOOLEAN LFH_validate_defer_block(ULONG flags, const LFH_block *block)
+{
+    const char *err = NULL;
+
+    if (!LFH_validate_block(flags, block))
+        return FALSE;
+    if (block->type != LFH_block_type_free)
+        err = "invalid defer block type";
+    else if (flags & HEAP_FREE_CHECKING_ENABLED)
+    {
+        const unsigned int *data = (const unsigned int *)LFH_ptr_from_block(block);
+        size_t class_size = LFH_block_get_class_size(block);
+        for (size_t i = 0; i < class_size / 4 - (data - (const unsigned int *)block) && !err; ++i)
+            if (data[i] != 0xfeeefeee) err = "invalid free filler";
+    }
+
+    if (err) WARN("%08x %p: %s\n", flags, block, err);
+    return err == NULL;
+}
+
+static inline BOOLEAN LFH_validate_used_block(ULONG flags, const LFH_block *block)
+{
+    const char *err = NULL;
+
+    if (!LFH_validate_block(flags, block))
+        return FALSE;
+    if (block->type != LFH_block_type_used)
+        err = "invalid used block type";
+    else if (flags & HEAP_TAIL_CHECKING_ENABLED)
+    {
+        const unsigned char *data = (const unsigned char *)LFH_ptr_from_block(block);
+        size_t alloc_size = LFH_block_get_alloc_size(block, flags);
+        for (size_t i = alloc_size; i < alloc_size + ALIGNMENT && !err; ++i)
+            if (data[i] != 0xab) err = "invalid tail filler";
+    }
+
+    if (err) WARN("%08x %p: %s\n", flags, block, err);
+    return err == NULL;
+}
+
+static BOOLEAN LFH_validate_arena_free_blocks(ULONG flags, const LFH_arena *arena)
+{
+    ssize_t offset = arena->next_free;
+    while (offset > 0)
+    {
+        LFH_block *block = LFH_arena_get_block(arena, offset);
+        if (!LFH_validate_free_block(flags, block))
+            return FALSE;
+        offset = block->next_free;
+    }
+
+    return TRUE;
+}
+
+static BOOLEAN LFH_validate_arena(ULONG flags, const LFH_arena *arena)
+{
+    const char *err = NULL;
+    const LFH_arena *parent;
+    const LFH_arena *block_arena = LFH_block_arena_from_block((LFH_block *)arena);
+    const LFH_arena *large_arena = LFH_large_arena_from_block((LFH_block *)arena);
+
+    if (flags & HEAP_VALIDATE)
+        return LFH_validate_heap(flags, LFH_heap_from_arena(arena));
+
+    if (arena != large_arena && arena != block_arena)
+        err = "invalid arena alignment";
+    else if (arena == block_arena)
+    {
+        if (!LFH_validate_block(flags, (LFH_block *)arena))
+            err = "invalid block arena";
+        else if (!LFH_validate_arena_free_blocks(flags, arena))
+            err = "invalid block arena free list";
+    }
+    else if (arena == large_arena && !LFH_class_from_arena(arena))
+    {
+        if (arena->huge_size <= LARGE_CLASS_MAX_SIZE)
+            err = "invalid huge arena size";
+    }
+    else if (arena == large_arena && (parent = LFH_parent_from_arena(arena)) != arena)
+    {
+        if (arena > parent || LFH_large_arena_from_block((LFH_block *)parent) != parent)
+            err = "invalid child arena parent";
+    }
+    else
+    {
+        if (!LFH_validate_arena_free_blocks(flags, arena))
+            err = "invalid large arena free list";
+    }
+
+    if (err) WARN("%08x %p: %s\n", flags, arena, err);
+    return err == NULL;
+}
+
+static BOOLEAN LFH_validate_class_arenas(ULONG flags, const LFH_class *class)
+{
+    LFH_arena *arena = class->next;
+    while (arena)
+    {
+        if (!LFH_validate_arena(flags, arena))
+            return FALSE;
+
+        arena = arena->class_entry;
+    }
+
+    return TRUE;
+}
+
+static BOOLEAN LFH_validate_heap_defer_blocks(ULONG flags, const LFH_heap *heap)
+{
+    const LFH_slist *entry = heap->list_defer;
+
+    while (entry)
+    {
+        const LFH_block *block = LIST_ENTRY(entry, LFH_block, entry_defer);
+        if (!LFH_validate_defer_block(flags, block))
+            return FALSE;
+        entry = entry->next;
+    }
+
+    return TRUE;
+}
+
+static BOOLEAN LFH_validate_heap(ULONG flags, const LFH_heap *heap)
+{
+    const char *err = NULL;
+    UINT i;
+
+    flags &= ~HEAP_VALIDATE;
+
+    if (heap != LFH_thread_heap(FALSE))
+        err = "unable to validate foreign heap";
+    else if (!LFH_validate_heap_defer_blocks(flags, heap))
+        err = "invalid heap defer blocks";
+    else
+    {
+        for (i = 0; err == NULL && i < TOTAL_BLOCK_CLASS_COUNT; ++i)
+        {
+            if (!LFH_validate_class_arenas(flags, &heap->block_class[i]))
+                return FALSE;
+        }
+
+        for (i = 0; err == NULL && i < TOTAL_LARGE_CLASS_COUNT; ++i)
+        {
+            if (!LFH_validate_class_arenas(flags, &heap->large_class[i]))
+                return FALSE;
+        }
+    }
+
+    if (err) WARN("%08x %p: %s\n", flags, heap, err);
+    return err == NULL;
+}
+
+static inline void LFH_block_initialize(LFH_block *block, ULONG flags, size_t old_size, size_t new_size, size_t class_size)
+{
+    char *ptr = (char *)LFH_ptr_from_block(block);
+
+    TRACE("block %p, flags %x, old_size %Ix, new_size %Ix, class_size %Ix, ptr %p\n", block, flags, old_size, new_size, class_size, ptr);
+
+    if ((flags & HEAP_ZERO_MEMORY) && new_size > old_size)
+        memset(ptr + old_size, 0, new_size - old_size);
+    else if ((flags & HEAP_FREE_CHECKING_ENABLED) && new_size > old_size && class_size < BLOCK_ARENA_SIZE)
+        memset(ptr + old_size, 0x55, new_size - old_size);
+
+    if ((flags & HEAP_TAIL_CHECKING_ENABLED))
+        memset(ptr + new_size, 0xab, ALIGNMENT);
+
+    block->type = LFH_block_type_used;
+    block->alloc_size = new_size;
+}
+
+static FORCEINLINE LFH_ptr *LFH_allocate(ULONG flags, size_t size)
+{
+    LFH_block *block = NULL;
+    LFH_class *class;
+    LFH_arena *arena;
+    LFH_heap *heap = LFH_thread_heap(TRUE);
+    size_t class_size = LFH_get_class_size(flags, size);
+
+    if (class_size == ~(size_t)0)
+        return NULL;
+
+    if (!LFH_deallocate_deferred_blocks(heap))
+        return NULL;
+
+    if ((class = LFH_heap_get_class(heap, class_size)))
+    {
+        arena = LFH_acquire_arena(heap, class);
+        if (arena) block = LFH_allocate_block(heap, class, arena);
+        if (block) LFH_block_initialize(block, flags, 0, size, LFH_block_get_class_size(block));
+    }
+    else
+    {
+        arena = LFH_allocate_huge_arena(heap, class_size);
+        if (arena) block = LFH_arena_get_block(arena, ARENA_HEADER_SIZE);
+        if (block) LFH_block_initialize(block, flags, 0, size, LFH_block_get_class_size(block));
+    }
+
+    LFH_deallocated_cached_arenas(heap);
+
+    if (!block) return NULL;
+    return LFH_ptr_from_block(block);
+}
+
+static FORCEINLINE BOOLEAN LFH_free(ULONG flags, LFH_ptr *ptr)
+{
+    LFH_block *block = LFH_block_from_ptr(ptr);
+    LFH_arena *arena = LFH_arena_from_block(block);
+    LFH_heap *heap = LFH_heap_from_arena(arena);
+
+    if (!LFH_class_from_arena(arena))
+        return LFH_memory_deallocate(arena, LFH_block_get_class_size(block));
+
+    if (flags & HEAP_FREE_CHECKING_ENABLED)
+    {
+        unsigned int *data = (unsigned int *)LFH_ptr_from_block(block);
+        size_t class_size = LFH_block_get_class_size(block);
+        for (size_t i = 0; i < class_size / 4 - (data - (const unsigned int *)block); ++i)
+            data[i] = 0xfeeefeee;
+    }
+
+    block->type = LFH_block_type_free;
+
+    if (heap == LFH_thread_heap(FALSE) && !(flags & HEAP_FREE_CHECKING_ENABLED))
+        LFH_deallocate_block(heap, LFH_arena_from_block(block), block);
+    else
+        LFH_slist_push(&heap->list_defer, &block->entry_defer);
+
+    return TRUE;
+}
+
+static FORCEINLINE LFH_ptr *LFH_reallocate(ULONG flags, LFH_ptr *old_ptr, size_t new_size)
+{
+    LFH_block *block = LFH_block_from_ptr(old_ptr);
+    LFH_arena *arena = LFH_arena_from_block(block);
+    LFH_heap *heap = LFH_heap_from_arena(arena);
+    size_t old_size = LFH_block_get_alloc_size(block, flags);
+    size_t old_class_size = LFH_block_get_class_size(block);
+    size_t new_class_size = LFH_get_class_size(flags, new_size);
+    LFH_class *new_class, *old_class = LFH_class_from_arena(arena);
+    LFH_ptr *new_ptr = NULL;
+
+    if (new_class_size == ~(size_t)0)
+        return NULL;
+
+    if (new_class_size <= old_class_size)
+        goto in_place;
+
+    if ((new_class = LFH_heap_get_class(heap, new_class_size)) && new_class == old_class)
+        goto in_place;
+
+    old_class_size = LFH_huge_alloc_size(old_class_size);
+    new_class_size = LFH_huge_alloc_size(new_class_size);
+    if (!new_class && !old_class && old_class_size == new_class_size)
+        goto in_place;
+
+    if (flags & HEAP_REALLOC_IN_PLACE_ONLY)
+        return NULL;
+
+    if (!(new_ptr = LFH_allocate(flags, new_size)))
+        return NULL;
+
+    memcpy(new_ptr, old_ptr, old_size);
+
+    if (LFH_free(flags, old_ptr))
+        return new_ptr;
+
+    LFH_free(flags, new_ptr);
+    return NULL;
+
+in_place:
+    LFH_block_initialize(block, flags, old_size, new_size, old_class_size);
+    return old_ptr;
+}
+
+static inline size_t LFH_get_allocated_size(ULONG flags, const LFH_ptr *ptr)
+{
+    const LFH_block *block = LFH_block_from_ptr(ptr);
+    return LFH_block_get_alloc_size(block, flags);
+}
+
+static inline void *LFH_get_user_info(ULONG flags, const LFH_ptr *ptr)
+{
+    const LFH_block *block = LFH_block_from_ptr(ptr);
+    size_t class_size = LFH_block_get_class_size(block);
+    return *(void **)((char *)block + class_size - ALIGNMENT);
+}
+
+static inline void LFH_set_user_info(ULONG flags, const LFH_ptr *ptr, void *user_value)
+{
+    const LFH_block *block = LFH_block_from_ptr(ptr);
+    size_t class_size = LFH_block_get_class_size(block);
+    *(void **)((char *)block + class_size - ALIGNMENT) = user_value;
+}
+
+static inline BOOLEAN LFH_validate(ULONG flags, const LFH_ptr *ptr)
+{
+    const LFH_block *block = LFH_block_from_ptr(ptr);
+    const LFH_heap *heap;
+
+    /* clear HEAP_VALIDATE so we only validate block */
+    if (ptr)
+        return LFH_validate_used_block(flags & ~HEAP_VALIDATE, block);
+
+    if (!(heap = LFH_thread_heap(FALSE)))
+        return TRUE;
+
+    return LFH_validate_heap(flags, heap);
+}
+
+static inline BOOLEAN LFH_try_validate_all(ULONG flags)
+{
+    if (!(flags & HEAP_VALIDATE_ALL))
+        return TRUE;
+
+    if (LFH_validate(flags, NULL))
+        return TRUE;
+
+    LFH_dump_heap(LFH_thread_heap(FALSE));
+    return FALSE;
+}
+
+NTSTATUS HEAP_lfh_allocate(HANDLE heap, ULONG flags, SIZE_T size, void **out)
+{
+    TRACE("heap %p, flags %08x, size %lx, out %p.\n", heap, flags, size, out);
+
+    if (!LFH_try_validate_all(flags))
+        return STATUS_INVALID_PARAMETER;
+
+    if (!(*out = LFH_allocate(flags, size)))
+        return STATUS_NO_MEMORY;
+
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS HEAP_lfh_free(HANDLE heap, ULONG flags, void *ptr)
+{
+    TRACE("heap %p, flags %08x, ptr %p.\n", heap, flags, ptr);
+
+    if (!LFH_try_validate_all(flags))
+        return STATUS_INVALID_PARAMETER;
+
+    if (!LFH_validate(flags, ptr))
+        return STATUS_INVALID_PARAMETER;
+
+    if (!LFH_free(flags, ptr))
+        return STATUS_INVALID_PARAMETER;
+
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS HEAP_lfh_reallocate(HANDLE heap, ULONG flags, void *ptr, SIZE_T size, void **out)
+{
+    TRACE("heap %p, flags %08x, ptr %p, size %lx, out %p.\n", heap, flags, ptr, size, out);
+
+    if (!LFH_try_validate_all(flags))
+        return STATUS_INVALID_PARAMETER;
+
+    if (!LFH_validate(flags, ptr))
+        return STATUS_INVALID_PARAMETER;
+
+    if (!(*out = LFH_reallocate(flags, ptr, size)))
+        return STATUS_NO_MEMORY;
+
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS HEAP_lfh_get_allocated_size(HANDLE heap, ULONG flags, const void *ptr, SIZE_T* out)
+{
+    TRACE("heap %p, flags %08x, ptr %p, out %p.\n", heap, flags, ptr, out);
+
+    if (!LFH_try_validate_all(flags))
+        return STATUS_INVALID_PARAMETER;
+
+    if (!LFH_validate(flags, ptr))
+        return STATUS_INVALID_PARAMETER;
+
+    *out = LFH_get_allocated_size(flags, ptr);
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS HEAP_lfh_validate(HANDLE heap, ULONG flags, const void *ptr)
+{
+    TRACE("heap %p, flags %08x, ptr %p.\n", heap, flags, ptr);
+
+    if (!LFH_try_validate_all(flags))
+        return STATUS_INVALID_PARAMETER;
+
+    if (!LFH_validate(flags, ptr))
+        return STATUS_INVALID_PARAMETER;
+
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS HEAP_lfh_get_user_info(HANDLE heap, ULONG flags, const void *ptr, void **user_value)
+{
+    TRACE("heap %p, flags %08x, ptr %p, user_value %p.\n", heap, flags, ptr, user_value);
+
+    if (!LFH_try_validate_all(flags))
+        return STATUS_INVALID_PARAMETER;
+
+    if (!LFH_validate(flags, ptr))
+        return STATUS_INVALID_PARAMETER;
+
+    *user_value = LFH_get_user_info(flags, ptr);
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS HEAP_lfh_set_user_info(HANDLE heap, ULONG flags, const void *ptr, void *user_value)
+{
+    TRACE("heap %p, flags %08x, ptr %p, user_value %p.\n", heap, flags, ptr, user_value);
+
+    if (!LFH_try_validate_all(flags))
+        return STATUS_INVALID_PARAMETER;
+
+    if (!LFH_validate(flags, ptr))
+        return STATUS_INVALID_PARAMETER;
+
+    LFH_set_user_info(flags, ptr, user_value);
+    return STATUS_SUCCESS;
 }
 
 void HEAP_lfh_notify_thread_destroy(BOOLEAN last)
 {
+    SLIST_HEADER *list_orphan = LFH_orphan_list();
+    SLIST_ENTRY *entry_orphan = NULL;
+    LFH_heap *heap;
+
+    if (last)
+    {
+        while ((entry_orphan || (entry_orphan = RtlInterlockedFlushSList(list_orphan))))
+        {
+            LFH_heap *orphan = LIST_ENTRY(entry_orphan, LFH_heap, entry_orphan);
+            entry_orphan = entry_orphan->Next;
+            LFH_heap_finalize(orphan);
+        }
+        LFH_memory_deallocate(list_orphan, BLOCK_ARENA_SIZE);
+    }
+    else if ((heap = LFH_thread_heap(FALSE)) && LFH_validate_heap(0, heap))
+        RtlInterlockedPushEntrySList(list_orphan, &heap->entry_orphan);
 }
 
 void HEAP_lfh_set_debug_flags(ULONG flags)
 {
+    LFH_heap *heap = LFH_thread_heap(FALSE);
+    if (!heap) return;
+
+    LFH_deallocate_deferred_blocks(heap);
+    LFH_deallocated_cached_arenas(heap);
 }
diff --git a/dlls/ntdll/unix/unix_private.h b/dlls/ntdll/unix/unix_private.h
index 3e99bc020da..b5c59ae7048 100644
--- a/dlls/ntdll/unix/unix_private.h
+++ b/dlls/ntdll/unix/unix_private.h
@@ -61,6 +61,7 @@ struct ntdll_thread_data
     PRTL_THREAD_START_ROUTINE start;  /* thread entry point */
     void              *param;         /* thread entry point parameter */
     void              *jmp_buf;       /* setjmp buffer for exception handling */
+    void              *heap;          /* thread local heap data */
 };
 
 C_ASSERT( sizeof(struct ntdll_thread_data) <= sizeof(((TEB *)0)->GdiTebBatch) );

From a2cad5dfc4ed88867963326db875eaff511e3440 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?R=C3=A9mi=20Bernon?= <rbernon@codeweavers.com>
Date: Fri, 9 Apr 2021 23:09:17 +0200
Subject: [PATCH 6/8] ntdll: Enable LFH for process heap.

---
 dlls/ntdll/loader.c | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/dlls/ntdll/loader.c b/dlls/ntdll/loader.c
index e27666b71f3..15ea4c7e339 100644
--- a/dlls/ntdll/loader.c
+++ b/dlls/ntdll/loader.c
@@ -4106,6 +4106,7 @@ void WINAPI LdrInitializeThunk( CONTEXT *context, ULONG_PTR unknown2, ULONG_PTR
         ANSI_STRING func_name;
         WINE_MODREF *kernel32;
         PEB *peb = NtCurrentTeb()->Peb;
+        DWORD hci = 2;
 
         peb->LdrData            = &ldr;
         peb->FastPebLock        = &peb_lock;
@@ -4129,6 +4130,7 @@ void WINAPI LdrInitializeThunk( CONTEXT *context, ULONG_PTR unknown2, ULONG_PTR
         wm->ldr.LoadCount = -1;
 
         build_ntdll_module();
+        RtlSetHeapInformation( GetProcessHeap(), HeapCompatibilityInformation, &hci, sizeof(hci) );
 
         if (NtCurrentTeb()->WowTebOffset) init_wow64( context );
 

From 63da75bd7b1d315d19d5534bd0f48031e7f3179c Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?R=C3=A9mi=20Bernon?= <rbernon@codeweavers.com>
Date: Tue, 5 May 2020 15:00:46 +0200
Subject: [PATCH 7/8] msvcrt: Enable LFH for internal heaps.

---
 dlls/msvcrt/heap.c | 4 ++++
 1 file changed, 4 insertions(+)

diff --git a/dlls/msvcrt/heap.c b/dlls/msvcrt/heap.c
index bf06c37e2c5..d187fbe9b8c 100644
--- a/dlls/msvcrt/heap.c
+++ b/dlls/msvcrt/heap.c
@@ -530,7 +530,9 @@ int CDECL _set_sbh_threshold(size_t threshold)
 
   if(!sb_heap)
   {
+      ULONG hci = 2;
       sb_heap = HeapCreate(0, 0, 0);
+      HeapSetInformation(sb_heap, HeapCompatibilityInformation, &hci, sizeof(hci));
       if(!sb_heap)
           return 0;
   }
@@ -829,7 +831,9 @@ int CDECL wmemcpy_s(wchar_t *dest, size_t numberOfElements,
 
 BOOL msvcrt_init_heap(void)
 {
+    ULONG hci = 2;
     heap = HeapCreate(0, 0, 0);
+    HeapSetInformation(heap, HeapCompatibilityInformation, &hci, sizeof(hci));
     return heap != NULL;
 }
 

From bdf808f787a20858b610424037bde2c7d193f60d Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?R=C3=A9mi=20Bernon?= <rbernon@codeweavers.com>
Date: Tue, 16 Mar 2021 18:57:40 +0100
Subject: [PATCH 8/8] ntdll: Force indirect branches for the error cases.

---
 dlls/ntdll/heap_lfh.c | 112 ++++++++++++++++++++++--------------------
 1 file changed, 60 insertions(+), 52 deletions(-)

diff --git a/dlls/ntdll/heap_lfh.c b/dlls/ntdll/heap_lfh.c
index 35c29630516..420402ab93f 100644
--- a/dlls/ntdll/heap_lfh.c
+++ b/dlls/ntdll/heap_lfh.c
@@ -26,6 +26,14 @@
 
 #include "ntdll_misc.h"
 
+#if defined(__GNUC__) || defined(__clang__)
+#define likely(x) __builtin_expect(!!(x), 1)
+#define unlikely(x) __builtin_expect(!!(x), 0)
+#else
+#define likely(x) x
+#define unlikely(x) x
+#endif
+
 WINE_DEFAULT_DEBUG_CHANNEL(heap);
 
 typedef struct LFH_ptr LFH_ptr;
@@ -711,26 +719,26 @@ static inline BOOLEAN LFH_validate_block(ULONG flags, const LFH_block *block)
     const LFH_arena *arena_arena = LFH_large_arena_from_block((LFH_block *)arena);
     const char *err = NULL;
 
-    if (flags & HEAP_VALIDATE)
+    if (unlikely(flags & HEAP_VALIDATE))
         return LFH_validate_arena(flags, arena);
 
-    if (!arena)
+    if (unlikely(!arena))
         err = "invalid arena";
-    else if (arena != arena_arena && arena != (arena_arena + 1))
+    else if (unlikely(arena != arena_arena && arena != (arena_arena + 1)))
         err = "invalid arena alignment";
-    else if (arena == block_arena)
+    else if (likely(arena == block_arena))
     {
-        if ((UINT_PTR)block < (UINT_PTR)block_arena + ARENA_HEADER_SIZE)
+        if (unlikely((UINT_PTR)block < (UINT_PTR)block_arena + ARENA_HEADER_SIZE))
             err = "invalid block alignment";
-        if (((UINT_PTR)block & (sizeof(*block) - 1)))
+        if (unlikely(((UINT_PTR)block & (sizeof(*block) - 1))))
             err = "invalid block alignment";
     }
-    else if (arena != large_arena)
+    else if (unlikely(arena != large_arena))
         err = "large/huge arena mismatch";
-    else if ((UINT_PTR)block != (UINT_PTR)block_arena)
+    else if (unlikely((UINT_PTR)block != (UINT_PTR)block_arena))
         err = "invalid block for large/huge arena";
 
-    if (err) WARN("%08x %p: %s\n", flags, block, err);
+    if (unlikely(err)) WARN("%08x %p: %s\n", flags, block, err);
     return err == NULL;
 }
 
@@ -738,12 +746,12 @@ static BOOLEAN LFH_validate_free_block(ULONG flags, const LFH_block *block)
 {
     const char *err = NULL;
 
-    if (!LFH_validate_block(flags, block))
+    if (unlikely(!LFH_validate_block(flags, block)))
         return FALSE;
-    if (block->type != LFH_block_type_free)
+    if (unlikely(block->type != LFH_block_type_free))
         err = "invalid free block type";
 
-    if (err) WARN("%08x %p: %s\n", flags, block, err);
+    if (unlikely(err)) WARN("%08x %p: %s\n", flags, block, err);
     return err == NULL;
 }
 
@@ -751,19 +759,19 @@ static BOOLEAN LFH_validate_defer_block(ULONG flags, const LFH_block *block)
 {
     const char *err = NULL;
 
-    if (!LFH_validate_block(flags, block))
+    if (unlikely(!LFH_validate_block(flags, block)))
         return FALSE;
-    if (block->type != LFH_block_type_free)
+    if (unlikely(block->type != LFH_block_type_free))
         err = "invalid defer block type";
-    else if (flags & HEAP_FREE_CHECKING_ENABLED)
+    else if (unlikely(flags & HEAP_FREE_CHECKING_ENABLED))
     {
         const unsigned int *data = (const unsigned int *)LFH_ptr_from_block(block);
         size_t class_size = LFH_block_get_class_size(block);
         for (size_t i = 0; i < class_size / 4 - (data - (const unsigned int *)block) && !err; ++i)
-            if (data[i] != 0xfeeefeee) err = "invalid free filler";
+            if (unlikely(data[i] != 0xfeeefeee)) err = "invalid free filler";
     }
 
-    if (err) WARN("%08x %p: %s\n", flags, block, err);
+    if (unlikely(err)) WARN("%08x %p: %s\n", flags, block, err);
     return err == NULL;
 }
 
@@ -771,11 +779,11 @@ static inline BOOLEAN LFH_validate_used_block(ULONG flags, const LFH_block *bloc
 {
     const char *err = NULL;
 
-    if (!LFH_validate_block(flags, block))
+    if (unlikely(!LFH_validate_block(flags, block)))
         return FALSE;
-    if (block->type != LFH_block_type_used)
+    if (unlikely(block->type != LFH_block_type_used))
         err = "invalid used block type";
-    else if (flags & HEAP_TAIL_CHECKING_ENABLED)
+    else if (unlikely(flags & HEAP_TAIL_CHECKING_ENABLED))
     {
         const unsigned char *data = (const unsigned char *)LFH_ptr_from_block(block);
         size_t alloc_size = LFH_block_get_alloc_size(block, flags);
@@ -783,7 +791,7 @@ static inline BOOLEAN LFH_validate_used_block(ULONG flags, const LFH_block *bloc
             if (data[i] != 0xab) err = "invalid tail filler";
     }
 
-    if (err) WARN("%08x %p: %s\n", flags, block, err);
+    if (unlikely(err)) WARN("%08x %p: %s\n", flags, block, err);
     return err == NULL;
 }
 
@@ -808,35 +816,35 @@ static BOOLEAN LFH_validate_arena(ULONG flags, const LFH_arena *arena)
     const LFH_arena *block_arena = LFH_block_arena_from_block((LFH_block *)arena);
     const LFH_arena *large_arena = LFH_large_arena_from_block((LFH_block *)arena);
 
-    if (flags & HEAP_VALIDATE)
+    if (unlikely(flags & HEAP_VALIDATE))
         return LFH_validate_heap(flags, LFH_heap_from_arena(arena));
 
-    if (arena != large_arena && arena != block_arena)
+    if (unlikely(arena != large_arena && arena != block_arena))
         err = "invalid arena alignment";
-    else if (arena == block_arena)
+    else if (unlikely(arena == block_arena))
     {
-        if (!LFH_validate_block(flags, (LFH_block *)arena))
+        if (unlikely(!LFH_validate_block(flags, (LFH_block *)arena)))
             err = "invalid block arena";
-        else if (!LFH_validate_arena_free_blocks(flags, arena))
+        else if (unlikely(!LFH_validate_arena_free_blocks(flags, arena)))
             err = "invalid block arena free list";
     }
-    else if (arena == large_arena && !LFH_class_from_arena(arena))
+    else if (unlikely(arena == large_arena && !LFH_class_from_arena(arena)))
     {
-        if (arena->huge_size <= LARGE_CLASS_MAX_SIZE)
+        if (unlikely(arena->huge_size <= LARGE_CLASS_MAX_SIZE))
             err = "invalid huge arena size";
     }
-    else if (arena == large_arena && (parent = LFH_parent_from_arena(arena)) != arena)
+    else if (unlikely(arena == large_arena && (parent = LFH_parent_from_arena(arena)) != arena))
     {
-        if (arena > parent || LFH_large_arena_from_block((LFH_block *)parent) != parent)
+        if (unlikely(arena > parent || LFH_large_arena_from_block((LFH_block *)parent) != parent))
             err = "invalid child arena parent";
     }
     else
     {
-        if (!LFH_validate_arena_free_blocks(flags, arena))
+        if (unlikely(!LFH_validate_arena_free_blocks(flags, arena)))
             err = "invalid large arena free list";
     }
 
-    if (err) WARN("%08x %p: %s\n", flags, arena, err);
+    if (unlikely(err)) WARN("%08x %p: %s\n", flags, arena, err);
     return err == NULL;
 }
 
@@ -895,7 +903,7 @@ static BOOLEAN LFH_validate_heap(ULONG flags, const LFH_heap *heap)
         }
     }
 
-    if (err) WARN("%08x %p: %s\n", flags, heap, err);
+    if (unlikely(err)) WARN("%08x %p: %s\n", flags, heap, err);
     return err == NULL;
 }
 
@@ -1047,7 +1055,7 @@ static inline BOOLEAN LFH_validate(ULONG flags, const LFH_ptr *ptr)
     const LFH_heap *heap;
 
     /* clear HEAP_VALIDATE so we only validate block */
-    if (ptr)
+    if (likely(ptr))
         return LFH_validate_used_block(flags & ~HEAP_VALIDATE, block);
 
     if (!(heap = LFH_thread_heap(FALSE)))
@@ -1058,10 +1066,10 @@ static inline BOOLEAN LFH_validate(ULONG flags, const LFH_ptr *ptr)
 
 static inline BOOLEAN LFH_try_validate_all(ULONG flags)
 {
-    if (!(flags & HEAP_VALIDATE_ALL))
+    if (likely(!(flags & HEAP_VALIDATE_ALL)))
         return TRUE;
 
-    if (LFH_validate(flags, NULL))
+    if (likely(LFH_validate(flags, NULL)))
         return TRUE;
 
     LFH_dump_heap(LFH_thread_heap(FALSE));
@@ -1072,10 +1080,10 @@ NTSTATUS HEAP_lfh_allocate(HANDLE heap, ULONG flags, SIZE_T size, void **out)
 {
     TRACE("heap %p, flags %08x, size %lx, out %p.\n", heap, flags, size, out);
 
-    if (!LFH_try_validate_all(flags))
+    if (unlikely(!LFH_try_validate_all(flags)))
         return STATUS_INVALID_PARAMETER;
 
-    if (!(*out = LFH_allocate(flags, size)))
+    if (unlikely(!(*out = LFH_allocate(flags, size))))
         return STATUS_NO_MEMORY;
 
     return STATUS_SUCCESS;
@@ -1085,13 +1093,13 @@ NTSTATUS HEAP_lfh_free(HANDLE heap, ULONG flags, void *ptr)
 {
     TRACE("heap %p, flags %08x, ptr %p.\n", heap, flags, ptr);
 
-    if (!LFH_try_validate_all(flags))
+    if (unlikely(!LFH_try_validate_all(flags)))
         return STATUS_INVALID_PARAMETER;
 
-    if (!LFH_validate(flags, ptr))
+    if (unlikely(!LFH_validate(flags, ptr)))
         return STATUS_INVALID_PARAMETER;
 
-    if (!LFH_free(flags, ptr))
+    if (unlikely(!LFH_free(flags, ptr)))
         return STATUS_INVALID_PARAMETER;
 
     return STATUS_SUCCESS;
@@ -1101,13 +1109,13 @@ NTSTATUS HEAP_lfh_reallocate(HANDLE heap, ULONG flags, void *ptr, SIZE_T size, v
 {
     TRACE("heap %p, flags %08x, ptr %p, size %lx, out %p.\n", heap, flags, ptr, size, out);
 
-    if (!LFH_try_validate_all(flags))
+    if (unlikely(!LFH_try_validate_all(flags)))
         return STATUS_INVALID_PARAMETER;
 
-    if (!LFH_validate(flags, ptr))
+    if (unlikely(!LFH_validate(flags, ptr)))
         return STATUS_INVALID_PARAMETER;
 
-    if (!(*out = LFH_reallocate(flags, ptr, size)))
+    if (unlikely(!(*out = LFH_reallocate(flags, ptr, size))))
         return STATUS_NO_MEMORY;
 
     return STATUS_SUCCESS;
@@ -1117,10 +1125,10 @@ NTSTATUS HEAP_lfh_get_allocated_size(HANDLE heap, ULONG flags, const void *ptr,
 {
     TRACE("heap %p, flags %08x, ptr %p, out %p.\n", heap, flags, ptr, out);
 
-    if (!LFH_try_validate_all(flags))
+    if (unlikely(!LFH_try_validate_all(flags)))
         return STATUS_INVALID_PARAMETER;
 
-    if (!LFH_validate(flags, ptr))
+    if (unlikely(!LFH_validate(flags, ptr)))
         return STATUS_INVALID_PARAMETER;
 
     *out = LFH_get_allocated_size(flags, ptr);
@@ -1131,10 +1139,10 @@ NTSTATUS HEAP_lfh_validate(HANDLE heap, ULONG flags, const void *ptr)
 {
     TRACE("heap %p, flags %08x, ptr %p.\n", heap, flags, ptr);
 
-    if (!LFH_try_validate_all(flags))
+    if (unlikely(!LFH_try_validate_all(flags)))
         return STATUS_INVALID_PARAMETER;
 
-    if (!LFH_validate(flags, ptr))
+    if (unlikely(!LFH_validate(flags, ptr)))
         return STATUS_INVALID_PARAMETER;
 
     return STATUS_SUCCESS;
@@ -1144,10 +1152,10 @@ NTSTATUS HEAP_lfh_get_user_info(HANDLE heap, ULONG flags, const void *ptr, void
 {
     TRACE("heap %p, flags %08x, ptr %p, user_value %p.\n", heap, flags, ptr, user_value);
 
-    if (!LFH_try_validate_all(flags))
+    if (unlikely(!LFH_try_validate_all(flags)))
         return STATUS_INVALID_PARAMETER;
 
-    if (!LFH_validate(flags, ptr))
+    if (unlikely(!LFH_validate(flags, ptr)))
         return STATUS_INVALID_PARAMETER;
 
     *user_value = LFH_get_user_info(flags, ptr);
@@ -1158,10 +1166,10 @@ NTSTATUS HEAP_lfh_set_user_info(HANDLE heap, ULONG flags, const void *ptr, void
 {
     TRACE("heap %p, flags %08x, ptr %p, user_value %p.\n", heap, flags, ptr, user_value);
 
-    if (!LFH_try_validate_all(flags))
+    if (unlikely(!LFH_try_validate_all(flags)))
         return STATUS_INVALID_PARAMETER;
 
-    if (!LFH_validate(flags, ptr))
+    if (unlikely(!LFH_validate(flags, ptr)))
         return STATUS_INVALID_PARAMETER;
 
     LFH_set_user_info(flags, ptr, user_value);
